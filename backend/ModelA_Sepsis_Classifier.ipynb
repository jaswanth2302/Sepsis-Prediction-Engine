{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Model A: Sepsis Risk Classifier (XGBoost)\n",
                "\n",
                "**Purpose**: Predict sepsis probability (0-100%) from patient vitals\n",
                "\n",
                "**Output**: `sepsis_model.pkl` - Used by the backend to calculate risk scores\n",
                "\n",
                "**Dataset**: Your cleaned `merged_sepsis_data.csv`\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Install Required Packages"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install required packages\n",
                "!pip install pandas numpy scikit-learn xgboost imbalanced-learn matplotlib seaborn --quiet\n",
                "print(\"âœ… All packages installed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Import Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import pickle\n",
                "import os\n",
                "from datetime import datetime\n",
                "\n",
                "# ML Libraries\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import (\n",
                "    accuracy_score, precision_score, recall_score, f1_score,\n",
                "    roc_auc_score, confusion_matrix, roc_curve\n",
                ")\n",
                "from xgboost import XGBClassifier\n",
                "from imblearn.over_sampling import SMOTE\n",
                "\n",
                "# Visualization\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print(f\"âœ… Libraries imported successfully!\")\n",
                "print(f\"   Timestamp: {datetime.now()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Load YOUR Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load your cleaned merged dataset\n",
                "DATA_PATH = '../merged_sepsis_data.csv'  # Adjust path if needed\n",
                "\n",
                "print(f\"Loading dataset from: {DATA_PATH}\")\n",
                "df = pd.read_csv(DATA_PATH)\n",
                "\n",
                "print(f\"\\nâœ… Dataset loaded successfully!\")\n",
                "print(f\"   Shape: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\n",
                "print(f\"   Patients: {df['Patient_ID'].nunique():,}\")\n",
                "print(f\"\\nSepsis distribution:\")\n",
                "print(f\"   Class 0 (No Sepsis): {(df['SepsisLabel'] == 0).sum():,} ({(df['SepsisLabel'] == 0).mean()*100:.1f}%)\")\n",
                "print(f\"   Class 1 (Sepsis):    {(df['SepsisLabel'] == 1).sum():,} ({(df['SepsisLabel'] == 1).mean()*100:.1f}%)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Preview the data\n",
                "print(\"Columns in dataset:\")\n",
                "print(list(df.columns))\n",
                "print(\"\\nFirst 5 rows:\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check vital sign ranges\n",
                "vital_cols = ['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp']\n",
                "print(\"Vital Sign Statistics:\")\n",
                "df[vital_cols].describe()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Feature Engineering\n",
                "\n",
                "Your data already has MAP. We'll add ShockIndex and HR_diff."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def engineer_features(df):\n",
                "    \"\"\"\n",
                "    Create derived features for sepsis prediction.\n",
                "    \"\"\"\n",
                "    df = df.copy()\n",
                "    \n",
                "    # Shock Index (normal: 0.5-0.7, elevated: >0.9)\n",
                "    # Avoid division by zero\n",
                "    df['ShockIndex'] = df['HR'] / df['SBP'].replace(0, np.nan)\n",
                "    df['ShockIndex'] = df['ShockIndex'].fillna(0.67)  # Default normal value\n",
                "    \n",
                "    # Heart rate change (difference from previous reading)\n",
                "    df['HR_diff'] = df.groupby('Patient_ID')['HR'].diff().fillna(0)\n",
                "    \n",
                "    # Clip extreme values\n",
                "    df['ShockIndex'] = df['ShockIndex'].clip(0, 5)\n",
                "    df['HR_diff'] = df['HR_diff'].clip(-50, 50)\n",
                "    \n",
                "    return df\n",
                "\n",
                "# Apply feature engineering\n",
                "print(\"Engineering features...\")\n",
                "df = engineer_features(df)\n",
                "\n",
                "print(f\"\\nâœ… Feature engineering complete!\")\n",
                "print(f\"   Added: ShockIndex, HR_diff\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Prepare Training Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define feature columns (EXACT ORDER - must match backend!)\n",
                "# Using columns that exist in YOUR dataset\n",
                "FEATURE_COLUMNS = [\n",
                "    'ICULOS',      # Hours since admission (renamed from your dataset)\n",
                "    'HR',          # Heart Rate\n",
                "    'O2Sat',       # SpO2\n",
                "    'Temp',        # Temperature\n",
                "    'SBP',         # Systolic BP\n",
                "    'MAP',         # Mean Arterial Pressure (already in your data)\n",
                "    'DBP',         # Diastolic BP\n",
                "    'Resp',        # Respiratory Rate\n",
                "    'ShockIndex',  # HR/SBP (calculated)\n",
                "    'HR_diff'      # Heart Rate change (calculated)\n",
                "]\n",
                "\n",
                "TARGET_COLUMN = 'SepsisLabel'\n",
                "\n",
                "# Verify all columns exist\n",
                "missing_cols = [c for c in FEATURE_COLUMNS if c not in df.columns]\n",
                "if missing_cols:\n",
                "    print(f\"âŒ Missing columns: {missing_cols}\")\n",
                "else:\n",
                "    print(f\"âœ… All feature columns found!\")\n",
                "\n",
                "# Extract features and target\n",
                "X = df[FEATURE_COLUMNS].copy()\n",
                "y = df[TARGET_COLUMN].copy()\n",
                "\n",
                "print(f\"\\nFeature matrix shape: {X.shape}\")\n",
                "print(f\"Target vector shape: {y.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Handle missing values\n",
                "print(\"Checking for missing values...\")\n",
                "missing = X.isnull().sum()\n",
                "missing_pct = (X.isnull().sum() / len(X)) * 100\n",
                "\n",
                "if missing.sum() > 0:\n",
                "    print(f\"\\nMissing values found:\")\n",
                "    for col in FEATURE_COLUMNS:\n",
                "        if missing[col] > 0:\n",
                "            print(f\"   {col}: {missing[col]:,} ({missing_pct[col]:.1f}%)\")\n",
                "    \n",
                "    # Fill with median\n",
                "    X = X.fillna(X.median())\n",
                "    print(\"\\nâœ… Missing values filled with median.\")\n",
                "else:\n",
                "    print(\"âœ… No missing values in feature columns.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sample data to speed up training (1.5M rows is huge)\n",
                "# You can adjust SAMPLE_SIZE or set to None to use all data\n",
                "\n",
                "SAMPLE_SIZE = 200000  # Use 200k samples for faster training\n",
                "\n",
                "if SAMPLE_SIZE and len(X) > SAMPLE_SIZE:\n",
                "    print(f\"Sampling {SAMPLE_SIZE:,} rows from {len(X):,} total...\")\n",
                "    \n",
                "    # Stratified sampling to maintain class balance\n",
                "    from sklearn.model_selection import train_test_split\n",
                "    X_sampled, _, y_sampled, _ = train_test_split(\n",
                "        X, y, \n",
                "        train_size=SAMPLE_SIZE,\n",
                "        stratify=y,\n",
                "        random_state=42\n",
                "    )\n",
                "    X = X_sampled\n",
                "    y = y_sampled\n",
                "    \n",
                "    print(f\"âœ… Sampled to {len(X):,} rows\")\n",
                "else:\n",
                "    print(f\"Using full dataset: {len(X):,} rows\")\n",
                "\n",
                "print(f\"\\nClass distribution after sampling:\")\n",
                "print(f\"   Class 0: {(y == 0).sum():,} ({(y == 0).mean()*100:.1f}%)\")\n",
                "print(f\"   Class 1: {(y == 1).sum():,} ({(y == 1).mean()*100:.1f}%)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train/Test Split\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, \n",
                "    test_size=0.2, \n",
                "    stratify=y, \n",
                "    random_state=42\n",
                ")\n",
                "\n",
                "print(f\"Training set: {X_train.shape[0]:,} samples\")\n",
                "print(f\"Test set:     {X_test.shape[0]:,} samples\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Handle class imbalance with SMOTE\n",
                "print(\"Applying SMOTE for class balancing...\")\n",
                "\n",
                "smote = SMOTE(random_state=42)\n",
                "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
                "\n",
                "print(f\"\\nâœ… SMOTE applied!\")\n",
                "print(f\"   Before: {len(X_train):,} samples\")\n",
                "print(f\"   After:  {len(X_train_balanced):,} samples\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 6: Train XGBoost Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Training XGBoost Classifier...\")\n",
                "print(\"(This may take a few minutes)\\n\")\n",
                "\n",
                "model = XGBClassifier(\n",
                "    n_estimators=200,\n",
                "    max_depth=6,\n",
                "    min_child_weight=2,\n",
                "    learning_rate=0.1,\n",
                "    subsample=0.8,\n",
                "    colsample_bytree=0.8,\n",
                "    reg_alpha=0.1,\n",
                "    reg_lambda=1.0,\n",
                "    objective='binary:logistic',\n",
                "    eval_metric='auc',\n",
                "    use_label_encoder=False,\n",
                "    random_state=42,\n",
                "    n_jobs=-1\n",
                ")\n",
                "\n",
                "model.fit(\n",
                "    X_train_balanced, \n",
                "    y_train_balanced,\n",
                "    eval_set=[(X_test, y_test)],\n",
                "    verbose=False\n",
                ")\n",
                "\n",
                "print(\"âœ… Model training complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 7: Evaluate Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Predictions\n",
                "y_pred = model.predict(X_test)\n",
                "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
                "\n",
                "# Metrics\n",
                "accuracy = accuracy_score(y_test, y_pred)\n",
                "precision = precision_score(y_test, y_pred)\n",
                "recall = recall_score(y_test, y_pred)\n",
                "f1 = f1_score(y_test, y_pred)\n",
                "auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
                "\n",
                "print(\"=\"*50)\n",
                "print(\"   MODEL PERFORMANCE METRICS\")\n",
                "print(\"=\"*50)\n",
                "print(f\"\\n   Accuracy:  {accuracy:.3f}\")\n",
                "print(f\"   Precision: {precision:.3f}\")\n",
                "print(f\"   Recall:    {recall:.3f}  â­ (Catch sepsis cases!)\")\n",
                "print(f\"   F1 Score:  {f1:.3f}\")\n",
                "print(f\"   AUC-ROC:   {auc_roc:.3f}\")\n",
                "print(\"\\n\" + \"=\"*50)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confusion Matrix\n",
                "cm = confusion_matrix(y_test, y_pred)\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
                "            xticklabels=['No Sepsis', 'Sepsis'],\n",
                "            yticklabels=['No Sepsis', 'Sepsis'])\n",
                "plt.xlabel('Predicted')\n",
                "plt.ylabel('Actual')\n",
                "plt.title('Confusion Matrix')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature Importance\n",
                "feature_importance = pd.DataFrame({\n",
                "    'Feature': FEATURE_COLUMNS,\n",
                "    'Importance': model.feature_importances_\n",
                "}).sort_values('Importance', ascending=True)\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.barh(feature_importance['Feature'], feature_importance['Importance'], color='steelblue')\n",
                "plt.xlabel('Feature Importance')\n",
                "plt.title('XGBoost Feature Importance')\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nTop 5 Features:\")\n",
                "print(feature_importance.tail(5).to_string(index=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 8: Save Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "MODEL_FILENAME = 'sepsis_model.pkl'\n",
                "\n",
                "model_package = {\n",
                "    'model': model,\n",
                "    'feature_columns': FEATURE_COLUMNS,\n",
                "    'version': '2.0',\n",
                "    'trained_at': datetime.now().isoformat(),\n",
                "    'metrics': {\n",
                "        'accuracy': float(accuracy),\n",
                "        'precision': float(precision),\n",
                "        'recall': float(recall),\n",
                "        'f1': float(f1),\n",
                "        'auc_roc': float(auc_roc)\n",
                "    },\n",
                "    'thresholds': {\n",
                "        'default': 0.5,\n",
                "        'high_sensitivity': 0.3,\n",
                "        'high_specificity': 0.7\n",
                "    }\n",
                "}\n",
                "\n",
                "with open(MODEL_FILENAME, 'wb') as f:\n",
                "    pickle.dump(model_package, f)\n",
                "\n",
                "file_size = os.path.getsize(MODEL_FILENAME) / 1024\n",
                "\n",
                "print(\"=\"*50)\n",
                "print(\"   MODEL SAVED!\")\n",
                "print(\"=\"*50)\n",
                "print(f\"\\n   ðŸ“ File: {MODEL_FILENAME}\")\n",
                "print(f\"   ðŸ“Š Size: {file_size:.1f} KB\")\n",
                "print(f\"   ðŸŽ¯ AUC-ROC: {auc_roc:.3f}\")\n",
                "print(\"\\n\" + \"=\"*50)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 9: Test Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def test_prediction(vitals: dict) -> dict:\n",
                "    \"\"\"Test model prediction.\"\"\"\n",
                "    with open('sepsis_model.pkl', 'rb') as f:\n",
                "        pkg = pickle.load(f)\n",
                "    \n",
                "    model = pkg['model']\n",
                "    \n",
                "    sbp = vitals.get('SBP', 120)\n",
                "    dbp = vitals.get('DBP', 80)\n",
                "    hr = vitals.get('HR', 80)\n",
                "    \n",
                "    MAP = (sbp + 2 * dbp) / 3\n",
                "    ShockIndex = hr / sbp if sbp > 0 else 0.67\n",
                "    \n",
                "    X = [[\n",
                "        vitals.get('ICULOS', 1),\n",
                "        hr,\n",
                "        vitals.get('O2Sat', 97),\n",
                "        vitals.get('Temp', 37.0),\n",
                "        sbp,\n",
                "        MAP,\n",
                "        dbp,\n",
                "        vitals.get('Resp', 18),\n",
                "        ShockIndex,\n",
                "        vitals.get('HR_diff', 0)\n",
                "    ]]\n",
                "    \n",
                "    prob = model.predict_proba(X)[0][1]\n",
                "    return {'risk': 'HIGH' if prob > 0.5 else 'LOW', 'probability': f\"{prob*100:.1f}%\"}\n",
                "\n",
                "# Test cases\n",
                "print(\"Testing model:\\n\")\n",
                "\n",
                "normal = {'HR': 75, 'Resp': 16, 'Temp': 37.0, 'SBP': 120, 'DBP': 80, 'O2Sat': 98, 'ICULOS': 5}\n",
                "print(f\"Normal vitals: {test_prediction(normal)}\")\n",
                "\n",
                "warning = {'HR': 105, 'Resp': 22, 'Temp': 38.5, 'SBP': 100, 'DBP': 65, 'O2Sat': 94, 'ICULOS': 12}\n",
                "print(f\"Warning signs: {test_prediction(warning)}\")\n",
                "\n",
                "critical = {'HR': 125, 'Resp': 28, 'Temp': 39.2, 'SBP': 85, 'DBP': 50, 'O2Sat': 88, 'ICULOS': 24}\n",
                "print(f\"Critical:      {test_prediction(critical)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## âœ… Model A Complete!\n",
                "\n",
                "**Next**: Run Model B notebook for vital forecaster.\n",
                "\n",
                "---"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}